# K-Means

#Using KMeans

from sklearn import datasets
# from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split

iris = datasets.load_iris()
features = iris.data
targets = iris.target

X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=5)

# scaler = StandardScaler()
# X_train = scaler.fit_transform(X_train)
# X_test = scaler.fit_transform(X_test)

cluster = KMeans(n_clusters=3, random_state=5)
model = cluster.fit(X_train,y_train)
y_pred = cluster.predict(X_train)

import numpy as np
#Getting unique labels
 
u_labels = np.unique(y_pred)
 
#plotting the results:
 
for i in u_labels:
    plt.scatter(X_train[y_pred == i , 0] , X_train[y_pred == i , 1] , label = i)
plt.legend()
plt.show()

#Getting the Centroids
centroids = cluster.cluster_centers_
u_labels = np.unique(y_pred)
 
#plotting the results:
 
for i in u_labels:
    plt.scatter(X_train[y_pred == i , 0] , X_train[y_pred == i , 1] , label = i)
plt.scatter(centroids[:,0] , centroids[:,1] , s = 80, color = 'k')
plt.legend()
plt.show()

y_test_pred = cluster.predict(X_test)

from sklearn.metrics import accuracy_score

print("Accuracy of Trainning set: ",accuracy_score(y_train,y_pred)*100,"%")
print("Accuracy of Test set: ",accuracy_score(y_test, y_test_pred)*100,"%")


'''
--------------------------
Custom
--------------------------
'''

import math
X = [2,3,4,10,11,12,20,25,30]
import numpy as np

m1 = X[np.random.randint(len(X))]
m2 = X[np.random.randint(len(X))]

print("Initial value of m1 and m2!!!")
print(m1)
print(m2)

while True:
    m1_old = m1
    m2_old = m2
    

    selected_clust = []
    som1 = 0
    som2 = 0

    count1 = 0
    count2 = 0

    for i in range(len(X)):
        
        val1 = abs(m1-X[i])
        val2 = abs(m2-X[i])

        if val1 < val2:
            selected_clust.append(0)
        else:
            selected_clust.append(1)

    print("Selected Cluster: ",selected_clust)

    for i in range(len(X)):
        if selected_clust[i] == 0:
            som1 = som1 + X[i]
            count1 = count1 + 1
        else:
            som2 = som2 + X[i]
            count2 = count2 + 1
        
    m1 = som1/count1
    m2 = som2/count2

    print("updated m1 and m2!!!")
    print(m1)
    print(m2)

    if (m1_old == m1) & (m2_old == m2):
        print("Previous m1 and m2 are same as current Stopping Clustering!!!")
        break


# With 3 clusters

X = [2,2,8,5,7,6,1,4]
y = [10,5,4,8,5,4,2,9]

# Random Clusters

import numpy as np

random_num1 = np.random.randint(len(X))
random_num2 = np.random.randint(len(X))
random_num3 = np.random.randint(len(X))

# We could have took any random number in our centroid but
# To avoid division by zero we will take 3 points from our data points

c1 = [X[random_num1],y[random_num1]]
c2 = [X[random_num2],y[random_num2]]
c3 = [X[random_num3],y[random_num3]]

# Custom Clusters

c1 = [2,10]
c2 = [5,8]
c3 = [1,2]

print("Initial Clusters")

print("c1= ",c1)
print("c2= ",c2)
print("c3= ",c3)

import math

while True:
    c1_old = c1
    c2_old = c2
    c3_old = c3
    

    selected_clust = []
    som1 = 0
    som2 = 0
    som3 = 0
    som4 = 0
    som5 = 0
    som6 = 0

    count1 = 0
    count2 = 0
    count3 = 0

    for i in range(len(X)):
        
        # Rectilenear Distance Formula
        # val1 = abs(c1[0]-X[i]) + abs(c1[1]-y[i])
        # val2 = abs(c2[0]-X[i]) + abs(c2[1]-y[i])
        # val3 = abs(c3[0]-X[i]) + abs(c3[1]-y[i])

        # Eucledian Distance Formula
        val1 = math.dist((c1[0],c1[1]),(X[i],y[i]))
        val2 = math.dist((c2[0],c2[1]),(X[i],y[i]))
        val3 = math.dist((c3[0],c3[1]),(X[i],y[i]))
        

        if val1 < val2:
            if val1 < val3:
                selected_clust.append(0)
            else:
                selected_clust.append(2)
        else:
            if val2 < val3:
                selected_clust.append(1)
            else:
                selected_clust.append(2)

    print("Selected Cluster: ",selected_clust)

    for i in range(len(X)):
        if selected_clust[i] == 0:
            som1 = som1 + X[i]
            som4 = som4 + y[i]
            count1 = count1 + 1
        
        elif selected_clust[i] == 1:
            som2 = som2 + X[i]
            som5 = som5 + y[i]
            count2 = count2 + 1

        else:
            som3 = som3 + X[i]
            som6 = som6 + y[i]
            count3 = count3 + 1
        
    c1 = [som1/count1 , som4/count1]
    c2 = [som2/count2 , som5/count2]
    c3 = [som3/count3, som6/count3]

    print("updated c1 and c2 and c3!!!")
    print(c1)
    print(c2)
    print(c3)

    if (c1_old == c1) & (c2_old == c2) & (c3_old == c3):
        print("Previous c1 and c2 and c3 are same as current Stopping Clustering!!!")
        break


# Verify values

# Find Centroid of Clusters of given dataset

from sklearn.cluster import KMeans
import numpy as np
X = np.array([[2,10],[2,5],[8,4],[5,8],[7,5],[6,4],[1,2],[4,9]])
kmeans = KMeans(n_clusters=3, random_state=0).fit(X)
# kmeans.labels_

# kmeans.predict([[0, 0], [12, 3]])

kmeans.cluster_centers_

# With 2 clusters

X = [2,2,8,5,7,6,1,4]
y = [10,5,4,8,5,4,2,9]

c1 = [2,10]
c2 = [5,8]

print("Initial value of c1 and c2!!!")
print(c1)
print(c2)

import math

while True:
    c1_old = c1
    c2_old = c2 

    selected_clust = []
    som1 = 0
    som2 = 0
    som3 = 0
    som4 = 0

    count1 = 0
    count2 = 0

    for i in range(len(X)):
        
        # Rectilenear Distance Formula
        # val1 = abs(c1[0]-X[i]) + abs(c1[1]-y[i])
        # val2 = abs(c2[0]-X[i]) + abs(c2[1]-y[i])

        # Eculedian Distance Formula
        val1 = math.dist((c1[0],c1[1]),(X[i],y[i]))
        val2 = math.dist((c2[0],c2[1]),(X[i],y[i]))

        if val1 < val2:
            selected_clust.append(0)

        else:
            selected_clust.append(1)

    print("Selected Cluster: ",selected_clust)

    for i in range(len(X)):
        if selected_clust[i] == 0:
            som1 = som1 + X[i]
            som2 = som2 + y[i]
            count1 = count1 + 1
        
        elif selected_clust[i] == 1:
            som3 = som3 + X[i]
            som4 = som4 + y[i]
            count2 = count2 + 1
        
    c1 = [som1/count1 , som2/count1]
    c2 = [som3/count2 , som4/count2]

    print("updated c1 and c2!!!")
    print(c1)
    print(c2)

    if (c1_old == c1) & (c2_old == c2):
        print("Previous c1 and c2 are same as current Stopping Clustering!!!")
        break


# Find Centroid of Clusters of given dataset

from sklearn.cluster import KMeans
import numpy as np
X = np.array([[2,10],[2,5],[8,4],[5,8],[7,5],[6,4],[1,2],[4,9]])
kmeans = KMeans(n_clusters=2, random_state=0).fit(X)
# kmeans.labels_

# kmeans.predict([[0, 0], [12, 3]])

kmeans.cluster_centers_


